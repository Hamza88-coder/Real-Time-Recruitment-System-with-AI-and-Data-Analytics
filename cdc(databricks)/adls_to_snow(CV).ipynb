{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: snowflake-connector-python in c:\\python\\python310\\lib\\site-packages (3.12.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python\\python310\\lib\\site-packages (from snowflake-connector-python) (2024.8.30)\n",
      "Requirement already satisfied: sortedcontainers>=2.4.0 in c:\\python\\python310\\lib\\site-packages (from snowflake-connector-python) (2.4.0)\n",
      "Requirement already satisfied: platformdirs<5.0.0,>=2.6.0 in c:\\python\\python310\\lib\\site-packages (from snowflake-connector-python) (4.3.6)\n",
      "Requirement already satisfied: cryptography>=3.1.0 in c:\\python\\python310\\lib\\site-packages (from snowflake-connector-python) (43.0.3)\n",
      "Requirement already satisfied: pyjwt<3.0.0 in c:\\python\\python310\\lib\\site-packages (from snowflake-connector-python) (2.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python\\python310\\lib\\site-packages (from snowflake-connector-python) (3.4.0)\n",
      "Requirement already satisfied: pytz in c:\\python\\python310\\lib\\site-packages (from snowflake-connector-python) (2024.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python\\python310\\lib\\site-packages (from snowflake-connector-python) (3.10)\n",
      "Requirement already satisfied: asn1crypto<2.0.0,>0.24.0 in c:\\python\\python310\\lib\\site-packages (from snowflake-connector-python) (1.5.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3 in c:\\python\\python310\\lib\\site-packages (from snowflake-connector-python) (4.12.2)\n",
      "Requirement already satisfied: tomlkit in c:\\python\\python310\\lib\\site-packages (from snowflake-connector-python) (0.13.2)\n",
      "Requirement already satisfied: packaging in c:\\python\\python310\\lib\\site-packages (from snowflake-connector-python) (24.1)\n",
      "Requirement already satisfied: filelock<4,>=3.5 in c:\\python\\python310\\lib\\site-packages (from snowflake-connector-python) (3.16.1)\n",
      "Requirement already satisfied: pyOpenSSL<25.0.0,>=16.2.0 in c:\\python\\python310\\lib\\site-packages (from snowflake-connector-python) (24.2.1)\n",
      "Requirement already satisfied: cffi<2.0.0,>=1.9 in c:\\python\\python310\\lib\\site-packages (from snowflake-connector-python) (1.17.1)\n",
      "Requirement already satisfied: requests<3.0.0 in c:\\python\\python310\\lib\\site-packages (from snowflake-connector-python) (2.32.3)\n",
      "Requirement already satisfied: pycparser in c:\\python\\python310\\lib\\site-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python) (2.22)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python\\python310\\lib\\site-packages (from requests<3.0.0->snowflake-connector-python) (1.26.20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\python\\python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install snowflake-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from delta.tables import DeltaTable\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowflake.connector\n",
    "import pandas as pd\n",
    "\n",
    "# Informations de connexion à Snowflake\n",
    "connection = snowflake.connector.connect(\n",
    "    user=\"SAID\",          # Remplacez par votre nom d'utilisateur\n",
    "    password=\"SaidKHALID2002!\",    # Remplacez par votre mot de passe\n",
    "    account='phztxrc-go36107',           # ID de votre compte (ex: xy12345.europe-west4)\n",
    "    warehouse=\"projet_warehouse\",     # Nom de votre entrepôt\n",
    "    database=\"my_project_database\",   # Nom de votre base de données\n",
    "    schema=\"my_project_schema\",       # Nom de votre schéma\n",
    "    role=\"dev_role\"                   # Rôle utilisé\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADLS_STORAGE_ACCOUNT_NAME = \"dataoffre\"\n",
    "ADLS_ACCOUNT_KEY = \"1eNXm2As1DuaMeSt2Yjegn22fFCvIUa8nBhknayEyTgfBZb6xEEyZhnvl9OiGT7U4O7cFrygjBE/+ASt1hkNQQ==\"\n",
    "ADLS_CONTAINER_NAME = \"offres\"\n",
    "ADLS_FOLDER_PATH = \"CV\"\n",
    "\n",
    "DELTA_SOURCE = f\"abfss://{ADLS_CONTAINER_NAME}@{ADLS_STORAGE_ACCOUNT_NAME}.dfs.core.windows.net/\"+ ADLS_FOLDER_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define checkpoint file path\n",
    "CHECKPOINT_FILE_PATH = \"./delta_checkpoint.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Spark session\n",
    "spark.conf.set(\n",
    "    f\"fs.azure.account.key.{ADLS_STORAGE_ACCOUNT_NAME}.dfs.core.windows.net\",\n",
    "    ADLS_ACCOUNT_KEY,\n",
    ")\n",
    "spark.conf.set(\"spark.databricks.delta.changeDataFeed.timestampOutOfRange.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the checkpoint file if it exists, otherwise set the LAST_READ_TIMESTAMP to 0\n",
    "delta_table = DeltaTable.forPath(spark, DELTA_SOURCE)\n",
    "try:\n",
    "    with open(CHECKPOINT_FILE_PATH, \"r\") as checkpoint_file:\n",
    "        LAST_READ_TIMESTAMP = checkpoint_file.read()\n",
    "    print(\"Getting Latest timtestamp from checkpoint file: \")\n",
    "except FileNotFoundError:\n",
    "    print(\"Getting Latest timtestamp from delta history: \")\n",
    "    LAST_READ_TIMESTAMP = (\n",
    "        delta_table.history().select(F.min(\"timestamp\").alias(\"timestamp\")).collect()\n",
    "    )\n",
    "    LAST_READ_TIMESTAMP = str(LAST_READ_TIMESTAMP[0][\"timestamp\"])\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LAST_READ_TIMESTAMP: \", LAST_READ_TIMESTAMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_data(connection, competences, date_birth,email,first_name,gender,nbr_exp, formation_nom, ecole_nom, last_name, telephone, ville_nom):\n",
    "    try:\n",
    "        ,ecole_id,email,first_name,formation_id,gender,last_name,nbr_exp,telephone ,ville_id\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        # Liste des compétences à insérer\n",
    "        for competence_nom in competences:\n",
    "            # Vérifier si la compétence existe déjà\n",
    "            cursor.execute(f\"\"\"\n",
    "                INSERT INTO my_project_schema.competence (COMPETENCE_ID, NOM)\n",
    "                SELECT \n",
    "                    COALESCE(MAX(competence_id), 0) + 1, -- ID auto-incrémenté si non trouvé\n",
    "                    '{competence_nom}'\n",
    "                FROM my_project_schema.competence\n",
    "                WHERE NOT EXISTS (\n",
    "                    SELECT 1 FROM my_project_schema.competence WHERE nom = '{competence_nom}'\n",
    "                );\n",
    "            \"\"\")\n",
    "\n",
    "        # Vérifier si l'école existe déjà et l'insérer\n",
    "        cursor.execute(f\"\"\"\n",
    "            INSERT INTO my_project_schema.ecole (ECOLE_ID, NOM)\n",
    "            SELECT \n",
    "                COALESCE(MAX(ecole_id), 0) + 1, -- ID auto-incrémenté si non trouvé\n",
    "                '{ecole_nom}'\n",
    "            FROM my_project_schema.ecole\n",
    "            WHERE NOT EXISTS (\n",
    "                SELECT 1 FROM my_project_schema.ecole WHERE nom = '{ecole_nom}'\n",
    "            );\n",
    "        \"\"\")\n",
    "        # Vérifier si l'école existe déjà et l'insérer\n",
    "        cursor.execute(f\"\"\"\n",
    "            INSERT INTO my_project_schema.ville (VILLE_ID, NOM)\n",
    "            SELECT \n",
    "                COALESCE(MAX(ecole_id), 0) + 1, -- ID auto-incrémenté si non trouvé\n",
    "                '{ville_nom}'\n",
    "            FROM my_project_schema.ecole\n",
    "            WHERE NOT EXISTS (\n",
    "                SELECT 1 FROM my_project_schema.ecole WHERE nom = '{ecole_nom}'\n",
    "            );\n",
    "        \"\"\")\n",
    "\n",
    "        # Insérer la formation si elle n'existe pas\n",
    "        cursor.execute(f\"\"\"\n",
    "            INSERT INTO my_project_schema.formation (FORMATION_ID, nom)\n",
    "            SELECT \n",
    "                COALESCE(MAX(formation_id), 0) + 1, -- ID auto-incrémenté si non trouvé\n",
    "                '{formation_nom}'\n",
    "            FROM my_project_schema.formation\n",
    "            WHERE NOT EXISTS (\n",
    "                SELECT 1 FROM my_project_schema.formation WHERE nom = '{formation_nom}'\n",
    "            );\n",
    "        \"\"\")\n",
    "\n",
    "        # Récupérer l'ID de la formation\n",
    "        cursor.execute(f\"\"\"\n",
    "            SELECT formation_id FROM my_project_schema.formation WHERE nom = '{formation_nom}'\n",
    "        \"\"\")\n",
    "        formation_id = cursor.fetchone()[0]\n",
    "         # Récupérer l'ID de la formation\n",
    "        cursor.execute(f\"\"\"\n",
    "            SELECT formation_id FROM my_project_schema.ville WHERE nom = '{ville_nom}'\n",
    "        \"\"\")\n",
    "        ville_id = cursor.fetchone()[0]\n",
    "\n",
    "       \n",
    "\n",
    "        # Récupérer l'ID de l'école\n",
    "        cursor.execute(f\"\"\"\n",
    "            SELECT ecole_id FROM my_project_schema.ecole WHERE nom = '{ecole_nom}'\n",
    "        \"\"\")\n",
    "        ecole_id = cursor.fetchone()[0]\n",
    "\n",
    "        # Insérer (candidat)\n",
    "        query = \"\"\"\n",
    "            INSERT INTO my_project_schema.candidat_fait (\n",
    "                date_birth,ecole_id, experience_dur, formation_id, contrat_id, typetrav_id, ecole_id, date_of_birth, email, first_name, last_name, nbr_exp, telephone, ville_id\n",
    "            )\n",
    "            SELECT \n",
    "                COALESCE(MAX(CANDIDAT_ID), 0) + 1, \n",
    "                %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s\n",
    "            FROM my_project_schema.offre_fait\n",
    "        \"\"\"\n",
    "        cursor.execute(query, (\n",
    "            date_birth,ecole_id,email,first_name,formation_id,gender,last_name,nbr_exp,telephone ,ville_id))\n",
    "\n",
    "        # Commit des modifications\n",
    "        connection.commit()\n",
    "\n",
    "        # Récupérer l'ID du candidat\n",
    "        cursor.execute(\"SELECT COALESCE(MAX(CANDIDAT_ID), 0) FROM my_project_schema.candidat_fait\")\n",
    "        candidat_id = cursor.fetchone()[0]\n",
    "\n",
    "        # Insertion des associations entre le candidat et les compétences\n",
    "        for competence_nom in competences:\n",
    "            # Récupérer l'ID de la compétence\n",
    "            cursor.execute(f\"\"\"\n",
    "                SELECT competence_id FROM my_project_schema.competence WHERE nom = '{competence_nom}'\n",
    "            \"\"\")\n",
    "            competence_id = cursor.fetchone()[0]\n",
    "\n",
    "            # Insérer l'association entre le candidat et la compétence\n",
    "            cursor.execute(f\"\"\"\n",
    "                INSERT INTO my_project_schema.candidat_comp(candidat_id, competence_id)\n",
    "                SELECT {candidat_id}, {competence_id}\n",
    "                WHERE NOT EXISTS (\n",
    "                    SELECT 1 FROM my_project_schema.candidat_comp WHERE candidat_id = {candidat_id} AND competence_id = {competence_id}\n",
    "                );\n",
    "            \"\"\")\n",
    "\n",
    "        # Commit des associations\n",
    "        connection.commit()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'insertion des données : {e}\")\n",
    "        connection.rollback()\n",
    "\n",
    "    finally:\n",
    "        cursor.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_langue_association(connection, langues):\n",
    "    try:\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        # Récupérer l'ID du candidat le plus récemment inséré\n",
    "        cursor.execute(f\"\"\"\n",
    "            SELECT COALESCE(MAX(CANDIDAT_ID), 0) FROM my_project_schema.candidat_fait\n",
    "        \"\"\")\n",
    "        candidat_id = cursor.fetchone()[0]\n",
    "\n",
    "        for langue_nom in langues:\n",
    "            # Vérifier si la langue existe déjà et obtenir l'ID de la langue\n",
    "            cursor.execute(f\"\"\"\n",
    "                SELECT langue_id FROM my_project_schema.langue WHERE nom = '{langue_nom}'\n",
    "            \"\"\")\n",
    "            langue_id = cursor.fetchone()[0]\n",
    "\n",
    "            # Insérer l'association candidat_id et langue_id dans la table d'association\n",
    "            cursor.execute(f\"\"\"\n",
    "                INSERT INTO my_project_schema.langue_cand (candidat_id, langue_id)\n",
    "                SELECT {candidat_id}, {langue_id}\n",
    "                WHERE NOT EXISTS (\n",
    "                    SELECT 1 \n",
    "                    FROM my_project_schema.langue_cand\n",
    "                    WHERE candidat_id = {candidat_id} \n",
    "                    AND langue_id = {langue_id}\n",
    "                );\n",
    "            \"\"\")\n",
    "\n",
    "        # Commit des modifications\n",
    "        connection.commit()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'insertion des associations : {e}\")\n",
    "        connection.rollback()\n",
    "\n",
    "    finally:\n",
    "        cursor.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_delta_changes():\n",
    "    delta_df = (\n",
    "        spark.read.format(\"delta\")\n",
    "        .option(\"readChangeFeed\", \"true\")\n",
    "        .option(\"startingTimestamp\", LAST_READ_TIMESTAMP)\n",
    "        .load(DELTA_SOURCE)\n",
    "    )\n",
    "\n",
    "    if delta_df.count() != 0:\n",
    "        excluded_columns = [\"_change_type\", \"_commit_version\", \"_commit_timestamp\"]\n",
    "        selected_columns = [\n",
    "            column for column in delta_df.columns if column not in excluded_columns\n",
    "        ]\n",
    "        print(f\"Colonnes sélectionnées : {selected_columns}\")\n",
    "        \n",
    "        # Filtrer les colonnes nécessaires et convertir en Pandas DataFrame\n",
    "        pandas_df = delta_df.select(*selected_columns).toPandas()\n",
    "        for index, row in pandas_df.iterrows():\n",
    "    # Assurez-vous que les noms de colonnes existent dans le DataFrame\n",
    "          # Extraire les paramètres de la ligne\n",
    "        \n",
    "         if row['experience_demande']==None:\n",
    "             row['experience_demande']=0\n",
    "      \n",
    "             \n",
    "    \n",
    "         insert_data(connection,row['competences'],row['date_birth'],row[' email'],row['first_name'] \n",
    "        , row['gender'],row['total_years_work_experience'],\n",
    "                     row[ 'education_details'][\"etude_title\"],row[ 'education_details'][  \"etablissement_name\"]\n",
    "                     row[\"last_name\"],row[\"phones\"],row[\"address\"][\"city\"])\n",
    "         insert_langue_association(connection ,row[\"langues\"])\n",
    "         updated_timestamp = delta_table.history().select(F.max(\"timestamp\").alias(\"timestamp\")).collect()[0][\"timestamp\"]\n",
    "         updated_timestamp += datetime.timedelta(seconds=1)\n",
    "         updated_timestamp = str(updated_timestamp)\n",
    "         print(\"Updated timestamp: \", updated_timestamp)\n",
    "         with open(CHECKPOINT_FILE_PATH, \"w\") as file:\n",
    "            file.write(updated_timestamp)\n",
    "\n",
    "    else:\n",
    "        print(\"Aucune nouvelle donnée dans les fichiers Delta.\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
